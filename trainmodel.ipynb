{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7e4bef-3abe-491c-b811-ca56c9378436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained successfully. RMSE: 11.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Load original user dataset\n",
    "df = pd.read_csv(\"Dating App Dataset.csv\")\n",
    "\n",
    "# Drop User ID\n",
    "user_profiles = df.drop(columns=[\"User ID\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(eval(list1)), set(eval(list2))\n",
    "    if not set1 or not set2:\n",
    "        return 0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def education_similarity(e1, e2):\n",
    "    levels = ['High School', \"Bachelor's Degree\", \"Master's Degree\", 'Ph.D.']\n",
    "    try:\n",
    "        return 1 - abs(levels.index(e1) - levels.index(e2)) / len(levels)\n",
    "    except ValueError:\n",
    "        return 0.5\n",
    "\n",
    "def occupation_similarity(o1, o2):\n",
    "    return 1 if o1 == o2 else 0\n",
    "\n",
    "def calculate_compatibility(user1, user2):\n",
    "    score = 0\n",
    "    if user1['Looking For'] == user2['Looking For']:\n",
    "        score += 20\n",
    "    if abs(user1['Age'] - user2['Age']) <= 5:\n",
    "        score += 10\n",
    "    score += jaccard_similarity(user1['Interests'], user2['Interests']) * 30\n",
    "    score += education_similarity(user1['Education Level'], user2['Education Level']) * 10\n",
    "    if user1['Frequency of Usage'] == user2['Frequency of Usage']:\n",
    "        score += 10\n",
    "    if user1['Children'] == user2['Children']:\n",
    "        score += 10\n",
    "    score += occupation_similarity(user1['Occupation'], user2['Occupation']) * 5\n",
    "    if abs(user1['Height'] - user2['Height']) < 0.5:\n",
    "        score += 5\n",
    "    return round(score, 2)\n",
    "\n",
    "# ---------- Generate Synthetic Pairs ----------\n",
    "\n",
    "num_pairs = 2000\n",
    "pairs = []\n",
    "\n",
    "for _ in range(num_pairs):\n",
    "    idx1, idx2 = random.sample(range(len(user_profiles)), 2)\n",
    "    u1 = user_profiles.iloc[idx1]\n",
    "    u2 = user_profiles.iloc[idx2]\n",
    "    compatibility = calculate_compatibility(u1, u2)\n",
    "\n",
    "    pairs.append({\n",
    "        \"User1_ID\": idx1,\n",
    "        \"User2_ID\": idx2,\n",
    "        \"User1_Gender\": u1[\"Gender\"],\n",
    "        \"User2_Gender\": u2[\"Gender\"],\n",
    "        \"User1_Age\": u1[\"Age\"],\n",
    "        \"User2_Age\": u2[\"Age\"],\n",
    "        \"User1_Interests\": u1[\"Interests\"],\n",
    "        \"User2_Interests\": u2[\"Interests\"],\n",
    "        \"User1_LookingFor\": u1[\"Looking For\"],\n",
    "        \"User2_LookingFor\": u2[\"Looking For\"],\n",
    "        \"User1_Children\": u1[\"Children\"],\n",
    "        \"User2_Children\": u2[\"Children\"],\n",
    "        \"User1_Education\": u1[\"Education Level\"],\n",
    "        \"User2_Education\": u2[\"Education Level\"],\n",
    "        \"User1_Occupation\": u1[\"Occupation\"],\n",
    "        \"User2_Occupation\": u2[\"Occupation\"],\n",
    "        \"User1_Usage\": u1[\"Frequency of Usage\"],\n",
    "        \"User2_Usage\": u2[\"Frequency of Usage\"],\n",
    "        \"User1_Height\": u1[\"Height\"],\n",
    "        \"User2_Height\": u2[\"Height\"],\n",
    "        \"CompatibilityScore\": compatibility\n",
    "    })\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs)\n",
    "\n",
    "# ---------- Preprocess & Train Model ----------\n",
    "\n",
    "# Define target and features\n",
    "features = pairs_df.drop(columns=[\"User1_ID\", \"User2_ID\", \"CompatibilityScore\"])\n",
    "target = pairs_df[\"CompatibilityScore\"]\n",
    "\n",
    "# Columns\n",
    "categorical_cols = [col for col in features.columns if \"Gender\" in col or\n",
    "                    \"LookingFor\" in col or \"Children\" in col or \"Education\" in col or\n",
    "                    \"Occupation\" in col or \"Usage\" in col]\n",
    "numerical_cols = [col for col in features.columns if \"Age\" in col or \"Height\" in col]\n",
    "\n",
    "# Interest similarity as a feature\n",
    "def transform_interests(df):\n",
    "    similarities = []\n",
    "    for i in range(len(df)):\n",
    "        similarities.append(jaccard_similarity(df.iloc[i][\"User1_Interests\"], df.iloc[i][\"User2_Interests\"]))\n",
    "    return pd.DataFrame({\"Interest_Similarity\": similarities})\n",
    "\n",
    "# Create interest similarity\n",
    "interest_similarity = transform_interests(features)\n",
    "features_model = features.drop(columns=[\"User1_Interests\", \"User2_Interests\"])\n",
    "features_model = pd.concat([features_model.reset_index(drop=True), interest_similarity], axis=1)\n",
    "\n",
    "# Preprocessor (Fix here)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numerical_cols + [\"Interest_Similarity\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "Pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),   # includes OneHotEncoder\n",
    "    (\"regressor\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_model, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"✅ Model trained successfully. RMSE: {rmse:.2f}\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model_pipeline, \"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
